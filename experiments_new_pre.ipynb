{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import io\n",
    "import re\n",
    "import random\n",
    "import numpy.random as npr\n",
    "from skimage import data\n",
    "from scipy.ndimage import rotate\n",
    "from kernels import *\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import os\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    " \n",
    "import my_utils as ut\n",
    "import old_utils_averaged_filters as old_ut_avg\n",
    "import old_utils_multi_image_old_snr as old_ut_multi\n",
    "from transformers import Swinv2ForImageClassification, SwinConfig\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms, datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# train_subset,val_subset, test_subset = ut.split_datasets(train_dataset, val_test_dataset, 30000, 3750, 3750)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m train_subset,val_subset, test_subset \u001b[38;5;241m=\u001b[39m ut\u001b[38;5;241m.\u001b[39msplit_datasets(train_dataset, val_test_dataset, \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_subset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     21\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_subset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 350\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/sampler.py:143\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "   \n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = ut.DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='train')\n",
    "val_test_dataset = ut.DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='val')\n",
    "\n",
    "\n",
    "train_subset,val_subset, test_subset = ut.split_datasets(train_dataset, val_test_dataset, 30000, 3750, 3750)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check overlap between datasets:\n",
      "\n",
      "\n",
      "Train Subset and Validation Subset:\n",
      "No actual data overlap detected.\n",
      "\n",
      "Train Subset and Test Subset:\n",
      "No actual data overlap detected.\n",
      "\n",
      "Validation Subset and Test Subset:\n",
      "No actual data overlap detected.\n",
      "\n",
      "\n",
      "Train Subset Distribution:\n",
      "\n",
      "Total samples in subset: 8\n",
      "Model ADM, Class nature: 1 (12.50%)\n",
      "Model BigGAN, Class nature: 1 (12.50%)\n",
      "Model Midjourney, Class nature: 1 (12.50%)\n",
      "Model VQDM, Class nature: 1 (12.50%)\n",
      "Model glide, Class ai: 1 (12.50%)\n",
      "Model stable_diffusion_v_1_4, Class nature: 1 (12.50%)\n",
      "Model stable_diffusion_v_1_5, Class nature: 1 (12.50%)\n",
      "Model wukong, Class nature: 1 (12.50%)\n",
      "\n",
      "Validation Subset Distribution:\n",
      "\n",
      "Total samples in subset: 8\n",
      "Model ADM, Class nature: 1 (12.50%)\n",
      "Model BigGAN, Class nature: 1 (12.50%)\n",
      "Model Midjourney, Class nature: 1 (12.50%)\n",
      "Model VQDM, Class ai: 1 (12.50%)\n",
      "Model glide, Class nature: 1 (12.50%)\n",
      "Model stable_diffusion_v_1_4, Class nature: 1 (12.50%)\n",
      "Model stable_diffusion_v_1_5, Class nature: 1 (12.50%)\n",
      "Model wukong, Class ai: 1 (12.50%)\n",
      "\n",
      "Test Subset Distribution:\n",
      "\n",
      "Total samples in subset: 8\n",
      "Model ADM, Class nature: 1 (12.50%)\n",
      "Model BigGAN, Class nature: 1 (12.50%)\n",
      "Model Midjourney, Class ai: 1 (12.50%)\n",
      "Model VQDM, Class nature: 1 (12.50%)\n",
      "Model glide, Class nature: 1 (12.50%)\n",
      "Model stable_diffusion_v_1_4, Class ai: 1 (12.50%)\n",
      "Model stable_diffusion_v_1_5, Class ai: 1 (12.50%)\n",
      "Model wukong, Class ai: 1 (12.50%)\n"
     ]
    }
   ],
   "source": [
    "#check distribution of classes \n",
    "\n",
    "print(\"Check overlap between datasets:\\n\")\n",
    "print(\"\\nTrain Subset and Validation Subset:\")\n",
    "ut.check_data_overlap(train_subset, val_subset)\n",
    "print(\"\\nTrain Subset and Test Subset:\")\n",
    "ut.check_data_overlap(train_subset, test_subset)\n",
    "print(\"\\nValidation Subset and Test Subset:\")\n",
    "ut.check_data_overlap(val_subset, test_subset)\n",
    "\n",
    "print()\n",
    "print(\"\\nTrain Subset Distribution:\\n\")\n",
    "ut.print_model_class_distribution(train_dataset, train_subset.indices)\n",
    "print(\"\\nValidation Subset Distribution:\\n\")\n",
    "ut.print_model_class_distribution(val_test_dataset, val_subset.indices)\n",
    "print(\"\\nTest Subset Distribution:\\n\")\n",
    "ut.print_model_class_distribution(val_test_dataset, test_subset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClassifier(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(BaseClassifier, self).__init__()\n",
    "        self.feature_combiner = ut.CNNBlock(kernels)\n",
    "        self.feature_combiner2 = ut.CNNBlock(kernels)\n",
    "        self.classifier = ut.DeepClassifier() \n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        outputs = self.classifier(feature_difference)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.feature_combiner = ut.CNNBlock(kernels)\n",
    "        self.feature_combiner2 = ut.CNNBlock(kernels)\n",
    "        resnet_weights = models.ResNet50_Weights.DEFAULT\n",
    "        self.resnet = models.resnet50(weights=resnet_weights)\n",
    "        # Remove the final fully connected layer\n",
    "        self.features = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "        # Add a new classifier layer\n",
    "        self.classifier = nn.Linear(self.resnet.fc.in_features, 2)\n",
    "        # Adaptive pool to make sure output from feature maps is of fixed size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        \n",
    "        # Process feature difference through the ResNet features\n",
    "        features = self.features(feature_difference)\n",
    "        pooled_features = self.adaptive_pool(features)\n",
    "        flat_features = torch.flatten(pooled_features, 1)\n",
    "        outputs = self.classifier(flat_features)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinClassification(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(SwinClassification, self).__init__()\n",
    "        self.feature_combiner = ut.CNNBlock(kernels)\n",
    "        self.feature_combiner2 = ut.CNNBlock(kernels)\n",
    "        config = SwinConfig.from_pretrained('microsoft/swinv2-tiny-patch4-window8-256',num_classes=2)\n",
    "        self.transformer = Swinv2ForImageClassification.from_pretrained(\n",
    "            \"microsoft/swinv2-tiny-patch4-window8-256\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        self.transformer.classifier = nn.Linear(config.hidden_size, 2) \n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        outputs = self.transformer(feature_difference)\n",
    "\n",
    "        return outputs.logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with freezing the pretrained models and only train the last layer with new preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swin Transformer\n",
    "learning_rates = [1e-3,1e-4, 1e-5 ]\n",
    "#print model and freeze and pre\n",
    "print(\"Training SWIN Transformer Frozen w/New Pre\\n\")\n",
    "\n",
    "for learning_rate in learning_rates: \n",
    "    print(f\"Training with Learning Rate for SWIN: {learning_rate} \\n\\n\")   \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kernels =  ut.apply_high_pass_filter()\n",
    "    model = SwinClassification(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_newPre_SWIN_frozen.pth'\n",
    "\n",
    "    #freeze the transformer layers\n",
    "    for param in model.transformer.parameters():\n",
    "        param.requires_grad = False\n",
    "    #unfreeze the classifier layer\n",
    "    for param in model.transformer.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNET\n",
    "print(\"Training RES Frozen w/New Pre\\n\")\n",
    "learning_rates = [1e-3,1e-4, 1e-5 ]\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kernels =  ut.apply_high_pass_filter()\n",
    "    model = ResNetClassifier(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_newPre_RESNET_frozen.pth'\n",
    "\n",
    "    #freeze resnet layers\n",
    "    for param in model.resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    #unfreeze the classifier layer\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze the pretrained model and Original Model with new preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swin Transformer\n",
    "learning_rates = [1e-3,1e-4, 1e-5, 1e-6]\n",
    "print(\"Training SWIN Transformer UNFrozen w/New Pre\\n\")\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kernels =  ut.apply_high_pass_filter()\n",
    "    model = SwinClassification(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_newPre_SWIN_unfrozen.pth'\n",
    "\n",
    "\n",
    "\n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Learning Rate: 0.001 \n",
      "\n",
      "\n",
      "Loaded previous best model with accuracy: 0.875\n",
      "Epoch 1/10\n",
      ",Train Loss: 0.7449, Train Acc: 0.2500, Val Loss: 0.5537, Val Acc: 0.7500\n",
      "\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.3480, Train Acc: 0.8750, Val Loss: 0.5469, Val Acc: 0.7500\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.0875, Train Acc: 1.0000, Val Loss: 0.5909, Val Acc: 0.7500\n",
      "\n",
      "Epoch 4/10\n",
      ",Train Loss: 0.0261, Train Acc: 1.0000, Val Loss: 0.5138, Val Acc: 0.7500\n",
      "\n",
      "Epoch 5/10\n",
      ",Train Loss: 0.0037, Train Acc: 1.0000, Val Loss: 0.4869, Val Acc: 0.7500\n",
      "\n",
      "Epoch 6/10\n",
      ",Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.4863, Val Acc: 0.7500\n",
      "\n",
      "Epoch 7/10\n",
      ",Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.5310, Val Acc: 0.7500\n",
      "\n",
      "Epoch 8/10\n",
      ",Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.5841, Val Acc: 0.7500\n",
      "\n",
      "Epoch 9/10\n",
      ",Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.6378, Val Acc: 0.7500\n",
      "\n",
      "Epoch 10/10\n",
      ",Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.6231, Val Acc: 0.7500\n",
      "\n",
      "Training with Learning Rate: 0.0001 \n",
      "\n",
      "\n",
      "Loaded previous best model with accuracy: 0.875\n",
      "Epoch 1/10\n",
      ",Train Loss: 0.6525, Train Acc: 0.8750, Val Loss: 0.6479, Val Acc: 0.8750\n",
      "\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.4225, Train Acc: 1.0000, Val Loss: 0.6195, Val Acc: 0.8750\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.3427, Train Acc: 1.0000, Val Loss: 0.6096, Val Acc: 0.8750\n",
      "\n",
      "Epoch 4/10\n",
      ",Train Loss: 0.2346, Train Acc: 1.0000, Val Loss: 0.6012, Val Acc: 0.7500\n",
      "\n",
      "Epoch 5/10\n",
      ",Train Loss: 0.1708, Train Acc: 1.0000, Val Loss: 0.5868, Val Acc: 0.7500\n",
      "\n",
      "Epoch 6/10\n",
      ",Train Loss: 0.1368, Train Acc: 1.0000, Val Loss: 0.5838, Val Acc: 0.7500\n",
      "\n",
      "Epoch 7/10\n",
      ",Train Loss: 0.1254, Train Acc: 1.0000, Val Loss: 0.5768, Val Acc: 0.7500\n",
      "\n",
      "Epoch 8/10\n",
      ",Train Loss: 0.0752, Train Acc: 1.0000, Val Loss: 0.5799, Val Acc: 0.7500\n",
      "\n",
      "Epoch 9/10\n",
      ",Train Loss: 0.0526, Train Acc: 1.0000, Val Loss: 0.5725, Val Acc: 0.7500\n",
      "\n",
      "Epoch 10/10\n",
      ",Train Loss: 0.0401, Train Acc: 1.0000, Val Loss: 0.5770, Val Acc: 0.7500\n",
      "\n",
      "Training with Learning Rate: 1e-05 \n",
      "\n",
      "\n",
      "Loaded previous best model with accuracy: 0.875\n",
      "Epoch 1/10\n",
      ",Train Loss: 0.6364, Train Acc: 0.7500, Val Loss: 0.6359, Val Acc: 0.8750\n",
      "\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.5785, Train Acc: 0.8750, Val Loss: 0.6374, Val Acc: 0.7500\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.5603, Train Acc: 1.0000, Val Loss: 0.6361, Val Acc: 0.7500\n",
      "\n",
      "Epoch 4/10\n",
      ",Train Loss: 0.5632, Train Acc: 1.0000, Val Loss: 0.6456, Val Acc: 0.7500\n",
      "\n",
      "Epoch 5/10\n",
      ",Train Loss: 0.5017, Train Acc: 1.0000, Val Loss: 0.6555, Val Acc: 0.7500\n",
      "\n",
      "Epoch 6/10\n",
      ",Train Loss: 0.5195, Train Acc: 1.0000, Val Loss: 0.6576, Val Acc: 0.7500\n",
      "\n",
      "Epoch 7/10\n",
      ",Train Loss: 0.4420, Train Acc: 1.0000, Val Loss: 0.6734, Val Acc: 0.7500\n",
      "\n",
      "Epoch 8/10\n",
      ",Train Loss: 0.4054, Train Acc: 1.0000, Val Loss: 0.6749, Val Acc: 0.7500\n",
      "\n",
      "Epoch 9/10\n",
      ",Train Loss: 0.4152, Train Acc: 0.8750, Val Loss: 0.6681, Val Acc: 0.7500\n",
      "\n",
      "Epoch 10/10\n",
      ",Train Loss: 0.3796, Train Acc: 1.0000, Val Loss: 0.6760, Val Acc: 0.7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ResNET\n",
    "print(\"Training RES UNFrozen w/New Pre\\n\")\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    \n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kernels =  ut.apply_high_pass_filter()\n",
    "    model = ResNetClassifier(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_newPre_RESNET_unfrozen.pth'\n",
    "\n",
    "\n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original model\n",
    "print(\"Training BASE w/New Pre\\n\")\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    \n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kernels =  ut.apply_high_pass_filter()\n",
    "    model = BaseClassifier(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_newPre_Base.pth'\n",
    "    \n",
    "    \n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
