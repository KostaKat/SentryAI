{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import io\n",
    "import re\n",
    "import random\n",
    "import numpy.random as npr\n",
    "from skimage import data\n",
    "from scipy.ndimage import rotate\n",
    "from kernels import *\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    " \n",
    "from collections import defaultdict\n",
    "import my_utils as ut\n",
    "from transformers import Swinv2ForImageClassification, SwinConfig\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms, datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "247\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class DatasetAI(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, split='train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split  # Can be 'train', 'val', or 'test'\n",
    "        self.samples = []\n",
    "\n",
    "        for model_name in sorted(os.listdir(root_dir)):\n",
    "            model_path = os.path.join(root_dir, model_name)\n",
    "            if os.path.isdir(model_path):\n",
    "                # Construct the imagenet directory path\n",
    "                imagenet_dir = f'imagenet_{model_name}'\n",
    "                data_dir = os.path.join(model_path, imagenet_dir, split)\n",
    "                if os.path.isdir(data_dir):\n",
    "                    for class_label in ['ai', 'nature']:\n",
    "                        class_path = os.path.join(data_dir, class_label)\n",
    "                        if os.path.exists(class_path):\n",
    "                            for img_name in os.listdir(class_path):\n",
    "                                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                                    img_path = os.path.join(class_path, img_name)\n",
    "                                    self.samples.append((img_path, class_label, model_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_label, model_name = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        rich, poor = ut.smash_n_reconstruct(image) \n",
    "        if self.transform:\n",
    "            rich = self.transform(rich)\n",
    "            poor = self.transform(poor)\n",
    "   \n",
    "        label = 0 if class_label == 'ai' else 1\n",
    "        # Return the model name along with the other data\n",
    "        return rich, poor, label, model_name\n",
    "\n",
    "\n",
    "\n",
    "def subset_train(dataset, desired_size, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Organize indices by both model and class\n",
    "    model_class_indices = defaultdict(list)\n",
    "    for idx, (_, class_label, model_name) in enumerate(dataset.samples):\n",
    "        model_class_indices[(model_name, class_label)].append(idx)\n",
    "    \n",
    "    # Determine the minimum size across all model-class combinations to ensure balance\n",
    "    min_group_size = min(len(indices) for indices in model_class_indices.values())\n",
    "    # Calculate the number of samples to select per model-class combination\n",
    "    samples_per_group = min(min_group_size, desired_size // len(model_class_indices))\n",
    "    \n",
    "    balanced_indices = []\n",
    "    for indices in model_class_indices.values():\n",
    "        selected_indices = rng.choice(indices, samples_per_group, replace=False)\n",
    "        balanced_indices.extend(selected_indices)\n",
    "    \n",
    "    # Shuffle the indices to ensure the dataset order does not introduce bias\n",
    "    rng.shuffle(balanced_indices)\n",
    "    \n",
    "    # Create the balanced training set\n",
    "    balanced_train_set = Subset(dataset, balanced_indices)\n",
    "    return balanced_train_set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def subset_val_test(dataset, val_size, test_size, seed=42):\n",
    "    rng = random.Random(seed)\n",
    "    model_class_indices = defaultdict(list)\n",
    "    for idx, (_, class_label, model_name) in enumerate(dataset.samples):\n",
    "        model_class_indices[(model_name, class_label)].append(idx)\n",
    "        \n",
    "\n",
    "    min_group_size = min(len(indices) for indices in model_class_indices.values())\n",
    "    val_samples_per_group = min(min_group_size, val_size // len(model_class_indices))\n",
    "\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    for indices in model_class_indices.values():\n",
    "        val_indices.extend(rng.sample(indices, val_samples_per_group))\n",
    "\n",
    "    all_val_indices = set(val_indices)\n",
    "\n",
    "    remaining_indices = [idx for idx in range(len(dataset)) if idx not in all_val_indices]\n",
    "\n",
    "    test_group_size = test_size // len(model_class_indices)\n",
    "\n",
    "    for indices in model_class_indices.values():\n",
    "        test_indices.extend(rng.sample([idx for idx in indices if idx in remaining_indices], test_group_size))\n",
    "\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    test_subset = Subset(dataset, test_indices)\n",
    "\n",
    "    return val_subset, test_subset\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "   \n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='train')\n",
    "val_test_dataset = DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='val')\n",
    "test_dalle = DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='val')\n",
    "# Balance the training dataset\n",
    "val_subset, test_subset = subset_val_test(val_test_dataset, 10000,10000)\n",
    "\n",
    "train_subset = subset_train(train_dataset, 30000)\n",
    "\n",
    "# Create DataLoader for each dataset\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    " \n",
    "\n",
    "train_set = set(train_subset.indices)\n",
    "val_set = set(val_subset.indices)\n",
    "test_set = set(test_subset.indices)\n",
    "\n",
    "\n",
    "# Find the intersection of these three sets\n",
    "intersection_trian_test = train_set.intersection(train_set, test_set)\n",
    "intersection_valid_train = train_set.intersection(train_set, val_set)\n",
    "intersection_val_test = val_set.intersection(val_set, test_set)\n",
    "\n",
    "\n",
    "print(len(intersection_trian_test))\n",
    "print(len(intersection_valid_train))\n",
    "print(len(intersection_val_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HighPassFilters(nn.Module):\n",
    "    def __init__(self, kernels):\n",
    "        super(HighPassFilters, self).__init__()\n",
    "        # Kernels are a parameter but not trained\n",
    "        self.kernels = nn.Parameter(kernels, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution with padding to maintain output size equal to input size\n",
    "        return F.conv2d(x, self.kernels, padding =2)  # Padding set to 2 to maintain output size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNBlock(nn.Module):\n",
    "   def __init__(self, kernals):\n",
    "       super(CNNBlock, self).__init__()\n",
    "       self.conv = nn.Conv2d(30, 3, kernel_size=1,padding=0)\n",
    "       self.filters = HighPassFilters(kernals)\n",
    "       self.bn = nn.BatchNorm2d(3)\n",
    "       self.htanh = nn.Hardtanh()\n",
    "   def forward(self, x):\n",
    "       x = self.filters(x)\n",
    "       x = self.conv(x)\n",
    "       x = self.bn(x)\n",
    "       x = self.htanh(x)\n",
    "       return x\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationModel(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(ImageClassificationModel, self).__init__()\n",
    "        self.feature_combiner = CNNBlock(kernels)\n",
    "        self.feature_combiner2 = CNNBlock(kernels)\n",
    "        config = SwinConfig.from_pretrained('microsoft/swinv2-tiny-patch4-window8-256',num_classes=2)\n",
    "        self.transformer = Swinv2ForImageClassification.from_pretrained(\n",
    "            \"microsoft/swinv2-tiny-patch4-window8-256\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        self.transformer.classifier = nn.Linear(config.hidden_size, 2) \n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        outputs = self.transformer(feature_difference)\n",
    "\n",
    "        return outputs.logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apply_high_pass_filter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5592/3984798118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkernels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_high_pass_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageClassificationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer = AdamW([\n",
      "\u001b[0;31mNameError\u001b[0m: name 'apply_high_pass_filter' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "kernels = ut.apply_high_pass_filter()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageClassificationModel(kernels).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW([\n",
    "    {'params': model.feature_combiner.parameters(), 'lr': 1e-4,},\n",
    "    {'params': model.feature_combiner2.parameters(), 'lr': 1e-4,},\n",
    "    {'params': model.transformer.parameters(), 'lr': 1e-4,}\n",
    "])\n",
    "# #freeze the transformer\n",
    "# for param in model.transformer.parameters():\n",
    "#     param.requires_grad = False\n",
    "# #unfreeze classifier\n",
    "# for param in model.transformer.classifier.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "best_val_accuracy = 0.0\n",
    "best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_newPatching_Crazy.pth'\n",
    "\n",
    "#\n",
    "# Try to load previous best model and its best validation accuracy\n",
    "try:\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    best_val_accuracy = checkpoint['best_val_accuracy']\n",
    "    print(\"Loaded previous best model with accuracy:\", best_val_accuracy)\n",
    "except FileNotFoundError:\n",
    "    best_val_accuracy = float('-inf')\n",
    "    print(\"No saved model found. Starting fresh!\")\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_and_validate(model, train_loader, valid_loader, optimizer, device, num_epochs, best_val_accuracy):\n",
    "    \n",
    "    best_val_accuracy_general = best_val_accuracy  # Use this to track the overall best accuracy\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss, total_train, correct_train = 0, 0, 0\n",
    "        for batch in train_loader:\n",
    "            rich, poor, labels, model_names = batch  # Unpack model_names as well\n",
    "            rich = rich.to(device)\n",
    "            poor = poor.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(rich, poor)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = total_train_loss / total_train\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_accuracy_per_model = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "        total_val_loss, total_val, correct_val = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                rich, poor, labels, model_names = batch  # Unpack model_names as well\n",
    "                rich = rich.to(device)\n",
    "                poor = poor.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(rich, poor)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_val_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "                # Collect stats per model\n",
    "                for model_name, pred, true in zip(model_names, predicted, labels):\n",
    "                    val_accuracy_per_model[model_name]['total'] += 1\n",
    "                    if pred == true:\n",
    "                        val_accuracy_per_model[model_name]['correct'] += 1\n",
    "\n",
    "        val_loss = total_val_loss / total_val\n",
    "        val_accuracy_general = correct_val / total_val\n",
    "\n",
    "        # Print overall validation accuracy\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}\\n,'\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy_general:.4f}\\n')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Check if general accuracy is the best and save\n",
    "        if val_accuracy_general > best_val_accuracy_general:\n",
    "            best_val_accuracy_general = val_accuracy_general\n",
    "            torch.save({'model_state': model.state_dict(),\n",
    "                        'best_val_accuracy': best_val_accuracy_general},\n",
    "                       best_model_path)\n",
    "            print(f\"Saved new best general model with accuracy: {best_val_accuracy_general:.4f}\")\n",
    "\n",
    "train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_val_accuracy=best_val_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageClassificationModel(kernels).to(device)\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    # Load the best model\n",
    "    checkpoint = torch.load(\"/home/kosta/code/School/SentryAI/pth/best_model_newPatching.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    \n",
    "    model.eval()\n",
    "    total_test, correct_test = 0, 0\n",
    "    test_accuracy_per_model = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            rich, poor, labels, model_names = batch  # Assuming you have model_names\n",
    "            rich = rich.to(device)\n",
    "            poor = poor.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(rich, poor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "            # Collect stats per model just like validation phase\n",
    "            for model_name, pred, true in zip(model_names, predicted, labels):\n",
    "                test_accuracy_per_model[model_name]['total'] += 1\n",
    "                if pred == true:\n",
    "                    test_accuracy_per_model[model_name]['correct'] += 1\n",
    "\n",
    "    test_accuracy = correct_test / total_test\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    # Print per model accuracy\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Test Accuracy per model:\")\n",
    "    for model_name, stats in test_accuracy_per_model.items():\n",
    "        model_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"Test Accuracy for model {model_name}: {model_accuracy:.4f}\")\n",
    "\n",
    "test(model, test_loader, device)\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(\"/home/kosta/code/School/SentryAI/pth/best_model_newPatching.pth\")\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the image path\n",
    "img_path = '/mnt/c/Users/kosta/Downloads/Screenshot 2024-04-28 002208.png'\n",
    "\n",
    "# Load the image\n",
    "rich, poor  = ut.smash_n_reconstruct(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "rich_tensor = transform(rich)\n",
    "poor_tensor = transform(poor)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(rich_tensor.unsqueeze(0).to(device), poor_tensor.unsqueeze(0).to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted class:\", predicted.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
