{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import io\n",
    "import re\n",
    "import random\n",
    "import numpy.random as npr\n",
    "from skimage import data\n",
    "from scipy.ndimage import rotate\n",
    "from kernels import *\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from utils import * \n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import Swinv2ForImageClassification, SwinConfig\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms, datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DatasetAI(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, split='train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split  # Can be 'train', 'val', or 'test'\n",
    "        self.samples = []\n",
    "\n",
    "        for model_name in sorted(os.listdir(root_dir)):\n",
    "            model_path = os.path.join(root_dir, model_name)\n",
    "            if os.path.isdir(model_path):\n",
    "                # Construct the imagenet directory path\n",
    "                imagenet_dir = f'imagenet_{model_name}'\n",
    "                data_dir = os.path.join(model_path, imagenet_dir, split)\n",
    "                if os.path.isdir(data_dir):\n",
    "                    for class_label in ['ai', 'nature']:\n",
    "                        class_path = os.path.join(data_dir, class_label)\n",
    "                        if os.path.exists(class_path):\n",
    "                            for img_name in os.listdir(class_path):\n",
    "                                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                                    img_path = os.path.join(class_path, img_name)\n",
    "                                    self.samples.append((img_path, class_label, model_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_label, model_name = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        rich, poor = smash_n_reconstruct(image) \n",
    "        if self.transform:\n",
    "            rich = self.transform(rich)\n",
    "            poor = self.transform(poor)\n",
    "   \n",
    "        label = 0 if class_label == 'ai' else 1\n",
    "        # Return the model name along with the other data\n",
    "        return rich, poor, label, model_name\n",
    "\n",
    "\n",
    "\n",
    "def subset_train(dataset, desired_size, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Organize indices by both model and class\n",
    "    model_class_indices = defaultdict(list)\n",
    "    for idx, (_, class_label, model_name) in enumerate(dataset.samples):\n",
    "        model_class_indices[(model_name, class_label)].append(idx)\n",
    "    \n",
    "    # Determine the minimum size across all model-class combinations to ensure balance\n",
    "    min_group_size = min(len(indices) for indices in model_class_indices.values())\n",
    "    # Calculate the number of samples to select per model-class combination\n",
    "    samples_per_group = min(min_group_size, desired_size // len(model_class_indices))\n",
    "    \n",
    "    balanced_indices = []\n",
    "    for indices in model_class_indices.values():\n",
    "        selected_indices = rng.choice(indices, samples_per_group, replace=False)\n",
    "        balanced_indices.extend(selected_indices)\n",
    "    \n",
    "    # Shuffle the indices to ensure the dataset order does not introduce bias\n",
    "    rng.shuffle(balanced_indices)\n",
    "    \n",
    "    # Create the balanced training set\n",
    "    balanced_train_set = Subset(dataset, balanced_indices)\n",
    "    return balanced_train_set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def subset_val_test(dataset, val_size, test_size, seed=42):\n",
    "    rng = random.Random(seed)\n",
    "    model_class_indices = defaultdict(list)\n",
    "    for idx, (_, class_label, model_name) in enumerate(dataset.samples):\n",
    "        model_class_indices[(model_name, class_label)].append(idx)\n",
    "        \n",
    "\n",
    "    min_group_size = min(len(indices) for indices in model_class_indices.values())\n",
    "    val_samples_per_group = min(min_group_size, val_size // len(model_class_indices))\n",
    "\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    for indices in model_class_indices.values():\n",
    "        val_indices.extend(rng.sample(indices, val_samples_per_group))\n",
    "\n",
    "    all_val_indices = set(val_indices)\n",
    "\n",
    "    remaining_indices = [idx for idx in range(len(dataset)) if idx not in all_val_indices]\n",
    "\n",
    "    test_group_size = test_size // len(model_class_indices)\n",
    "\n",
    "    for indices in model_class_indices.values():\n",
    "        test_indices.extend(rng.sample([idx for idx in indices if idx in remaining_indices], test_group_size))\n",
    "\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    test_subset = Subset(dataset, test_indices)\n",
    "\n",
    "    return val_subset, test_subset\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "   \n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='train')\n",
    "val_test_dataset = DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='val')\n",
    "test_dalle = DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='val')\n",
    "# Balance the training dataset\n",
    "val_subset, test_subset = subset_val_test(val_test_dataset, 20000,20000)\n",
    "\n",
    "train_subset = subset_train(train_dataset, 800000)\n",
    "\n",
    "# Create DataLoader for each dataset\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HighPassFilters(nn.Module):\n",
    "    def __init__(self, kernels):\n",
    "        super(HighPassFilters, self).__init__()\n",
    "        # Kernels are a parameter but not trained\n",
    "        self.kernels = nn.Parameter(kernels, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution with padding to maintain output size equal to input size\n",
    "        return F.conv2d(x, self.kernels, padding =2)  # Padding set to 2 to maintain output size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNBlock(nn.Module):\n",
    "   def __init__(self, kernals):\n",
    "       super(CNNBlock, self).__init__()\n",
    "       self.conv = nn.Conv2d(30, 3, kernel_size=1,padding=0)\n",
    "       self.filters = HighPassFilters(kernals)\n",
    "       self.bn = nn.BatchNorm2d(3)\n",
    "       self.htanh = nn.Hardtanh()\n",
    "   def forward(self, x):\n",
    "       x = self.filters(x)\n",
    "       x = self.conv(x)\n",
    "       x = self.bn(x)\n",
    "       x = self.htanh(x)\n",
    "       return x\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationModel(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(ImageClassificationModel, self).__init__()\n",
    "        self.feature_combiner = CNNBlock(kernels)\n",
    "        self.feature_combiner2 = CNNBlock(kernels)\n",
    "        config = SwinConfig.from_pretrained('microsoft/swinv2-tiny-patch4-window8-256',num_classes=2)\n",
    "        self.transformer = Swinv2ForImageClassification.from_pretrained(\n",
    "            \"microsoft/swinv2-tiny-patch4-window8-256\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        self.transformer.classifier = nn.Linear(config.hidden_size, 2) \n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        outputs = self.transformer(feature_difference)\n",
    "\n",
    "        return outputs.logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type swinv2 to instantiate a model of type swin. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved model found. Starting fresh!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_114074/1812888197.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved new best general model with accuracy: {best_val_accuracy_general:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_114074/1812888197.py\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, valid_loader, optimizer, device, num_epochs, best_val_accuracy)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mtotal_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "kernels = apply_high_pass_filter()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageClassificationModel(kernels).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW([\n",
    "    {'params': model.feature_combiner.parameters(), 'lr': 1e-4,},\n",
    "    {'params': model.feature_combiner2.parameters(), 'lr': 1e-4,},\n",
    "    {'params': model.transformer.parameters(), 'lr': 1e-4,}\n",
    "])\n",
    "# #freeze the transformer\n",
    "# for param in model.transformer.parameters():\n",
    "#     param.requires_grad = False\n",
    "# #unfreeze classifier\n",
    "# for param in model.transformer.classifier.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "best_val_accuracy = 0.0\n",
    "best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_newPatching_Crazy.pth'\n",
    "\n",
    "#\n",
    "# Try to load previous best model and its best validation accuracy\n",
    "try:\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    best_val_accuracy = checkpoint['best_val_accuracy']\n",
    "    print(\"Loaded previous best model with accuracy:\", best_val_accuracy)\n",
    "except FileNotFoundError:\n",
    "    best_val_accuracy = float('-inf')\n",
    "    print(\"No saved model found. Starting fresh!\")\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_and_validate(model, train_loader, valid_loader, optimizer, device, num_epochs, best_val_accuracy):\n",
    "    \n",
    "    best_val_accuracy_general = best_val_accuracy  # Use this to track the overall best accuracy\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss, total_train, correct_train = 0, 0, 0\n",
    "        for batch in train_loader:\n",
    "            rich, poor, labels, model_names = batch  # Unpack model_names as well\n",
    "            rich = rich.to(device)\n",
    "            poor = poor.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(rich, poor)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = total_train_loss / total_train\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_accuracy_per_model = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "        total_val_loss, total_val, correct_val = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                rich, poor, labels, model_names = batch  # Unpack model_names as well\n",
    "                rich = rich.to(device)\n",
    "                poor = poor.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(rich, poor)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_val_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "                # Collect stats per model\n",
    "                for model_name, pred, true in zip(model_names, predicted, labels):\n",
    "                    val_accuracy_per_model[model_name]['total'] += 1\n",
    "                    if pred == true:\n",
    "                        val_accuracy_per_model[model_name]['correct'] += 1\n",
    "\n",
    "        val_loss = total_val_loss / total_val\n",
    "        val_accuracy_general = correct_val / total_val\n",
    "\n",
    "        # Print overall validation accuracy\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}\\n,'\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy_general:.4f}\\n')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Check if general accuracy is the best and save\n",
    "        if val_accuracy_general > best_val_accuracy_general:\n",
    "            best_val_accuracy_general = val_accuracy_general\n",
    "            torch.save({'model_state': model.state_dict(),\n",
    "                        'best_val_accuracy': best_val_accuracy_general},\n",
    "                       best_model_path)\n",
    "            print(f\"Saved new best general model with accuracy: {best_val_accuracy_general:.4f}\")\n",
    "\n",
    "train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_val_accuracy=best_val_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type swinv2 to instantiate a model of type swin. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9909\n",
      "-------------------------------------------------------------------------\n",
      "Test Accuracy per model:\n",
      "Test Accuracy for model ADM: 0.9919\n",
      "Test Accuracy for model BigGAN: 0.9919\n",
      "Test Accuracy for model Midjourney: 0.9919\n",
      "Test Accuracy for model VQDM: 1.0000\n",
      "Test Accuracy for model glide: 0.9839\n",
      "Test Accuracy for model stable_diffusion_v_1_4: 0.9758\n",
      "Test Accuracy for model stable_diffusion_v_1_5: 0.9919\n",
      "Test Accuracy for model wukong: 1.0000\n",
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from utils import apply_high_pass_filter\n",
    "from utils import smash_n_reconstruct\n",
    "kernels = apply_high_pass_filter()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageClassificationModel(kernels).to(device)\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    # Load the best model\n",
    "    checkpoint = torch.load(\"/home/kosta/code/School/SentryAI/pth/best_model_newPatching.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    \n",
    "    model.eval()\n",
    "    total_test, correct_test = 0, 0\n",
    "    test_accuracy_per_model = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            rich, poor, labels, model_names = batch  # Assuming you have model_names\n",
    "            rich = rich.to(device)\n",
    "            poor = poor.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(rich, poor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "            # Collect stats per model just like validation phase\n",
    "            for model_name, pred, true in zip(model_names, predicted, labels):\n",
    "                test_accuracy_per_model[model_name]['total'] += 1\n",
    "                if pred == true:\n",
    "                    test_accuracy_per_model[model_name]['correct'] += 1\n",
    "\n",
    "    test_accuracy = correct_test / total_test\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    # Print per model accuracy\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Test Accuracy per model:\")\n",
    "    for model_name, stats in test_accuracy_per_model.items():\n",
    "        model_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"Test Accuracy for model {model_name}: {model_accuracy:.4f}\")\n",
    "\n",
    "test(model, test_loader, device)\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(\"/home/kosta/code/School/SentryAI/pth/best_model_newPatching.pth\")\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the image path\n",
    "img_path = '/mnt/c/Users/kosta/Downloads/Screenshot 2024-04-28 002208.png'\n",
    "\n",
    "# Load the image\n",
    "rich, poor  = smash_n_reconstruct(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "rich_tensor = transform(rich)\n",
    "poor_tensor = transform(poor)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(rich_tensor.unsqueeze(0).to(device), poor_tensor.unsqueeze(0).to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted class:\", predicted.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
