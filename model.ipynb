{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import io\n",
    "import re\n",
    "import random\n",
    "import numpy.random as npr\n",
    "from skimage import data\n",
    "from scipy.ndimage import rotate\n",
    "from kernels import *\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    " \n",
    "import my_utils as ut\n",
    "from transformers import Swinv2ForImageClassification, SwinConfig\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms, datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "   \n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = ut.DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='train')\n",
    "val_test_dataset = ut.DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='val')\n",
    "\n",
    "\n",
    "train_subset,val_subset, test_subset = ut.split_datasets(train_dataset, val_test_dataset, 300, 300, 300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check overlap between datasets:\n",
      "Train Subset and Validation Subset:\n",
      "No actual data overlap detected.\n",
      "Train Subset and Test Subset:\n",
      "No actual data overlap detected.\n",
      "Validation Subset and Test Subset:\n",
      "No actual data overlap detected.\n",
      "Train Subset Distribution:\n",
      "Total samples in subset: 296\n",
      "Model ADM, Class ai: 20 (6.76%)\n",
      "Model ADM, Class nature: 17 (5.74%)\n",
      "Model BigGAN, Class nature: 20 (6.76%)\n",
      "Model BigGAN, Class ai: 17 (5.74%)\n",
      "Model Midjourney, Class ai: 21 (7.09%)\n",
      "Model Midjourney, Class nature: 16 (5.41%)\n",
      "Model VQDM, Class nature: 11 (3.72%)\n",
      "Model VQDM, Class ai: 26 (8.78%)\n",
      "Model glide, Class nature: 18 (6.08%)\n",
      "Model glide, Class ai: 19 (6.42%)\n",
      "Model stable_diffusion_v_1_4, Class nature: 22 (7.43%)\n",
      "Model stable_diffusion_v_1_4, Class ai: 15 (5.07%)\n",
      "Model stable_diffusion_v_1_5, Class nature: 19 (6.42%)\n",
      "Model stable_diffusion_v_1_5, Class ai: 18 (6.08%)\n",
      "Model wukong, Class ai: 22 (7.43%)\n",
      "Model wukong, Class nature: 15 (5.07%)\n",
      "\n",
      "Validation Subset Distribution:\n",
      "Total samples in subset: 296\n",
      "Model ADM, Class nature: 21 (7.09%)\n",
      "Model ADM, Class ai: 16 (5.41%)\n",
      "Model BigGAN, Class nature: 27 (9.12%)\n",
      "Model BigGAN, Class ai: 10 (3.38%)\n",
      "Model Midjourney, Class nature: 21 (7.09%)\n",
      "Model Midjourney, Class ai: 16 (5.41%)\n",
      "Model VQDM, Class ai: 17 (5.74%)\n",
      "Model VQDM, Class nature: 20 (6.76%)\n",
      "Model glide, Class nature: 19 (6.42%)\n",
      "Model glide, Class ai: 18 (6.08%)\n",
      "Model stable_diffusion_v_1_4, Class nature: 16 (5.41%)\n",
      "Model stable_diffusion_v_1_4, Class ai: 21 (7.09%)\n",
      "Model stable_diffusion_v_1_5, Class nature: 14 (4.73%)\n",
      "Model stable_diffusion_v_1_5, Class ai: 23 (7.77%)\n",
      "Model wukong, Class ai: 20 (6.76%)\n",
      "Model wukong, Class nature: 17 (5.74%)\n",
      "\n",
      "Test Subset Distribution:\n",
      "Total samples in subset: 296\n",
      "Model ADM, Class ai: 20 (6.76%)\n",
      "Model ADM, Class nature: 17 (5.74%)\n",
      "Model BigGAN, Class nature: 19 (6.42%)\n",
      "Model BigGAN, Class ai: 18 (6.08%)\n",
      "Model Midjourney, Class ai: 21 (7.09%)\n",
      "Model Midjourney, Class nature: 16 (5.41%)\n",
      "Model VQDM, Class ai: 21 (7.09%)\n",
      "Model VQDM, Class nature: 16 (5.41%)\n",
      "Model glide, Class ai: 18 (6.08%)\n",
      "Model glide, Class nature: 19 (6.42%)\n",
      "Model stable_diffusion_v_1_4, Class nature: 19 (6.42%)\n",
      "Model stable_diffusion_v_1_4, Class ai: 18 (6.08%)\n",
      "Model stable_diffusion_v_1_5, Class ai: 16 (5.41%)\n",
      "Model stable_diffusion_v_1_5, Class nature: 21 (7.09%)\n",
      "Model wukong, Class nature: 18 (6.08%)\n",
      "Model wukong, Class ai: 19 (6.42%)\n"
     ]
    }
   ],
   "source": [
    "#check distribution of classes \n",
    "\n",
    "print(\"Check overlap between datasets:\")\n",
    "print(\"Train Subset and Validation Subset:\")\n",
    "ut.check_data_overlap(train_subset, val_subset)\n",
    "print(\"Train Subset and Test Subset:\")\n",
    "ut.check_data_overlap(train_subset, test_subset)\n",
    "print(\"Validation Subset and Test Subset:\")\n",
    "ut.check_data_overlap(val_subset, test_subset)\n",
    "\n",
    "print(\"Train Subset Distribution:\")\n",
    "ut.print_model_class_distribution(train_dataset, train_subset.indices)\n",
    "print(\"\\nValidation Subset Distribution:\")\n",
    "ut.print_model_class_distribution(val_test_dataset, val_subset.indices)\n",
    "print(\"\\nTest Subset Distribution:\")\n",
    "ut.print_model_class_distribution(val_test_dataset, test_subset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HighPassFilters(nn.Module):\n",
    "    def __init__(self, kernels):\n",
    "        super(HighPassFilters, self).__init__()\n",
    "        # Kernels are a parameter but not trained\n",
    "        self.kernels = nn.Parameter(kernels, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution with padding to maintain output size equal to input size\n",
    "        return F.conv2d(x, self.kernels, padding =2)  # Padding set to 2 to maintain output size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNBlock(nn.Module):\n",
    "   def __init__(self, kernals):\n",
    "       super(CNNBlock, self).__init__()\n",
    "       self.conv = nn.Conv2d(30, 3, kernel_size=1,padding=0)\n",
    "       self.filters = HighPassFilters(kernals)\n",
    "       self.bn = nn.BatchNorm2d(3)\n",
    "       self.htanh = nn.Hardtanh()\n",
    "   def forward(self, x):\n",
    "       x = self.filters(x)\n",
    "       x = self.conv(x)\n",
    "       x = self.bn(x)\n",
    "       x = self.htanh(x)\n",
    "       return x\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationModel(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(ImageClassificationModel, self).__init__()\n",
    "        self.feature_combiner = CNNBlock(kernels)\n",
    "        self.feature_combiner2 = CNNBlock(kernels)\n",
    "        config = SwinConfig.from_pretrained('microsoft/swinv2-tiny-patch4-window8-256',num_classes=2)\n",
    "        self.transformer = Swinv2ForImageClassification.from_pretrained(\n",
    "            \"microsoft/swinv2-tiny-patch4-window8-256\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        self.transformer.classifier = nn.Linear(config.hidden_size, 2) \n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        outputs = self.transformer(feature_difference)\n",
    "\n",
    "        return outputs.logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type swinv2 to instantiate a model of type swin. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous best model with accuracy: 0.9970619658119658\n",
      "Epoch 1/10\n",
      ",Train Loss: 0.6827, Train Acc: 0.5270, Val Loss: 0.6573, Val Acc: 0.6520\n",
      "\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.6511, Train Acc: 0.6723, Val Loss: 0.6312, Val Acc: 0.6892\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.6015, Train Acc: 0.7432, Val Loss: 0.5871, Val Acc: 0.7264\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 91\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Try to load previous best model and its best validation accuracy\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#                        best_model_path)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m             \u001b[38;5;66;03m# print(f\"Saved new best model with accuracy: {best_val_accuracy_general:.4f}\")\u001b[39;00m\n\u001b[1;32m     90\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/kosta/code/School/SentryAI/pth/best_model_newPatching_fixed_subset.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 91\u001b[0m \u001b[43mut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/School/SentryAI/my_utils.py:190\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, valid_loader, optimizer, device, num_epochs, best_model_path)\u001b[0m\n\u001b[1;32m    188\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(rich, poor)\n\u001b[1;32m    189\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 190\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    193\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "kernels = ut.apply_high_pass_filter()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageClassificationModel(kernels).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW([\n",
    "    {'params': model.feature_combiner.parameters(), 'lr': 1e-5,},\n",
    "    {'params': model.feature_combiner2.parameters(), 'lr': 1e-5,},\n",
    "    {'params': model.transformer.parameters(), 'lr': 1e-5,}\n",
    "])\n",
    "# #freeze the transformer\n",
    "# for param in model.transformer.parameters():\n",
    "#     param.requires_grad = False\n",
    "# #unfreeze classifier\n",
    "# for param in model.transformer.classifier.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "#\n",
    "# Try to load previous best model and its best validation accuracy\n",
    "\n",
    "\n",
    "def train_and_validate(model, train_loader, valid_loader, optimizer, \n",
    "                       device, num_epochs,best_model_path):\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        best_val_accuracy = checkpoint['best_val_accuracy']\n",
    "        print(\"Loaded previous best model with accuracy:\", best_val_accuracy)\n",
    "    except FileNotFoundError:\n",
    "        best_val_accuracy = float('-inf')\n",
    "        print(\"No saved model found. Starting fresh!\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss, total_train, correct_train = 0, 0, 0\n",
    "        for batch in train_loader:\n",
    "            rich, poor, labels, model_names = batch  # Unpack model_names as well\n",
    "            rich = rich.to(device)\n",
    "            poor = poor.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(rich, poor)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = total_train_loss / total_train\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        total_val_loss, total_val, correct_val = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                rich, poor, labels, model_names = batch  # Unpack model_names as well\n",
    "                rich = rich.to(device)\n",
    "                poor = poor.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(rich, poor)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_val_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = total_val_loss / total_val\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        # Print overall validation accuracy\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}\\n,'\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\\n')\n",
    "        \n",
    "        # Check if general accuracy is the best and save\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy_general = val_accuracy\n",
    "            torch.save({'model_state': model.state_dict(),\n",
    "                        'best_val_accuracy': best_val_accuracy_general},\n",
    "                       best_model_path)\n",
    "            print(f\"Saved new best model with accuracy: {best_val_accuracy_general:.4f}\")\n",
    "best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_newPatching_fixed_subset.pth'\n",
    "train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path=best_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type swinv2 to instantiate a model of type swin. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m         model_accuracy \u001b[38;5;241m=\u001b[39m stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy for model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m total_test \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m correct_test \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Collect stats per model just like validation phase\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, pred, true \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_names, predicted, labels):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageClassificationModel(kernels).to(device)\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    # Load the best model\n",
    "    checkpoint = torch.load(\"/home/kosta/code/School/SentryAI/pth/best_model_newPatching.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    \n",
    "    model.eval()\n",
    "    total_test, correct_test = 0, 0\n",
    "    test_accuracy_per_model = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            rich, poor, labels, model_names = batch  # Assuming you have model_names\n",
    "            rich = rich.to(device)\n",
    "            poor = poor.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(rich, poor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "            # Collect stats per model just like validation phase\n",
    "            for model_name, pred, true in zip(model_names, predicted, labels):\n",
    "                test_accuracy_per_model[model_name]['total'] += 1\n",
    "                if pred == true:\n",
    "                    test_accuracy_per_model[model_name]['correct'] += 1\n",
    "\n",
    "    test_accuracy = correct_test / total_test\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    # Print per model accuracy\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Test Accuracy per model:\")\n",
    "    for model_name, stats in test_accuracy_per_model.items():\n",
    "        model_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"Test Accuracy for model {model_name}: {model_accuracy:.4f}\")\n",
    "\n",
    "test(model, test_loader, device)\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(\"/home/kosta/code/School/SentryAI/pth/best_model_newPatching.pth\")\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the image path\n",
    "img_path = '/mnt/c/Users/kosta/Downloads/Screenshot 2024-04-28 002208.png'\n",
    "\n",
    "# Load the image\n",
    "rich, poor  = ut.smash_n_reconstruct(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "rich_tensor = transform(rich)\n",
    "poor_tensor = transform(poor)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(rich_tensor.unsqueeze(0).to(device), poor_tensor.unsqueeze(0).to(device))\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted class:\", predicted.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
