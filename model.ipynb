{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "import io\n",
    "import random\n",
    "from skimage import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproccessing \n",
    "This includes augmentations, smash and reconstruction of the image, and  high pass filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the image processing functions\n",
    "def jpeg_compression(img, quality_range=(70, 100)):\n",
    "    if random.random() < 0.1:  # 10% probability\n",
    "        quality = random.randint(*quality_range)\n",
    "        img_bytes = io.BytesIO()\n",
    "        img.save(img_bytes, format='JPEG', quality=quality)\n",
    "        img = Image.open(img_bytes)\n",
    "    return img\n",
    "\n",
    "def gaussian_blur(img, sigma_range=(0, 1)):\n",
    "    if random.random() < 0.1:  # 10% probability\n",
    "        sigma = random.uniform(*sigma_range)\n",
    "        img = img.filter(ImageFilter.GaussianBlur(sigma))\n",
    "    return img\n",
    "\n",
    "def downsampling(img, scale_range=(0.25, 0.5)):\n",
    "    if random.random() < 0.1:  # 10% probability\n",
    "        scale = random.uniform(*scale_range)\n",
    "        smaller_img = img.resize((int(img.width * scale), int(img.height * scale)), Image.BICUBIC)\n",
    "        img = smaller_img.resize((img.width, img.height), Image.BICUBIC)\n",
    "    return img\n",
    "\n",
    "# Load a sample image and convert it to a PIL Image\n",
    "numpy_image = data.astronaut()\n",
    "img = Image.fromarray(numpy_image)\n",
    "\n",
    "# Apply the image processing functions\n",
    "img_compressed = jpeg_compression(img)\n",
    "img_blurred = gaussian_blur(img)\n",
    "img_downsampled = downsampling(img)\n",
    "\n",
    "# Display the processed images to verify the changes\n",
    "img_compressed.show()\n",
    "img_blurred.show()\n",
    "img_downsampled.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Classifier\n",
    "\n",
    "The following deep classifier has the following layers:\n",
    "| **Type**    |**Kernel  num**| **With BN** | **Activation** |\n",
    "| ------------| ------------  | -------     | ----------     |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Avg Pooling | None          | None        | None           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Avg Pooling | None          | None        | None           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Avg Pooling | None          | None        | None           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| Convo.      | 32            | TRUE        | ReLU           |\n",
    "| AdpAvgPool  | None          | None        | None           |\n",
    "| Flatten     | None          | None        | None           |\n",
    "| FC          | None          | FALSE       | None           |\n",
    "\n",
    "Source: https://arxiv.org/pdf/2311.12397.pdf (page 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "class DeepClassifier(nn.Module):\n",
    "    def __init__(self, num_classes= 1): \n",
    "        super(DeepClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "        self.conv6 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.conv7 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(32)\n",
    "        self.conv8 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(32)\n",
    "        self.conv9 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(32)\n",
    "        self.conv10 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn10 = nn.BatchNorm2d(32)\n",
    "        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = self.avg_pool(x)\n",
    "        x = F.relu(self.bn9(self.conv9(x)))\n",
    "        x = F.relu(self.bn10(self.conv10(x)))\n",
    "        x = self.adaptive_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = DeepClassifier()\n",
    "\n",
    "\n",
    "example_input = torch.rand(4, 3, 64, 64)\n",
    "\n",
    "output = model(example_input)\n",
    "print(output.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
