{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import io\n",
    "import re\n",
    "import random\n",
    "import numpy.random as npr\n",
    "from skimage import data\n",
    "from scipy.ndimage import rotate\n",
    "from kernels import *\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import os\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    " \n",
    "import my_utils as ut\n",
    "import old_utils_averaged_filters as old_ut_avg\n",
    "import old_utils_multi_image_old_snr as old_ut_multi\n",
    "from transformers import Swinv2ForImageClassification, SwinConfig\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms, datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "   \n",
    "])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = old_ut_multi.DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='train')\n",
    "val_test_dataset = old_ut_multi.DatasetAI(root_dir='/mnt/e/GenImage', transform=transform, split='val')\n",
    "\n",
    "\n",
    "train_subset,val_subset, test_subset = ut.split_datasets(train_dataset, val_test_dataset, 30000, 3750, 3750)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check overlap between datasets:\n",
      "\n",
      "\n",
      "Train Subset and Validation Subset:\n",
      "No actual data overlap detected.\n",
      "\n",
      "Train Subset and Test Subset:\n",
      "No actual data overlap detected.\n",
      "\n",
      "Validation Subset and Test Subset:\n",
      "No actual data overlap detected.\n",
      "\n",
      "\n",
      "Train Subset Distribution:\n",
      "\n",
      "Total samples in subset: 296\n",
      "Model ADM, Class ai: 20 (6.76%)\n",
      "Model ADM, Class nature: 17 (5.74%)\n",
      "Model BigGAN, Class nature: 20 (6.76%)\n",
      "Model BigGAN, Class ai: 17 (5.74%)\n",
      "Model Midjourney, Class ai: 21 (7.09%)\n",
      "Model Midjourney, Class nature: 16 (5.41%)\n",
      "Model VQDM, Class nature: 11 (3.72%)\n",
      "Model VQDM, Class ai: 26 (8.78%)\n",
      "Model glide, Class nature: 18 (6.08%)\n",
      "Model glide, Class ai: 19 (6.42%)\n",
      "Model stable_diffusion_v_1_4, Class nature: 22 (7.43%)\n",
      "Model stable_diffusion_v_1_4, Class ai: 15 (5.07%)\n",
      "Model stable_diffusion_v_1_5, Class nature: 19 (6.42%)\n",
      "Model stable_diffusion_v_1_5, Class ai: 18 (6.08%)\n",
      "Model wukong, Class ai: 22 (7.43%)\n",
      "Model wukong, Class nature: 15 (5.07%)\n",
      "\n",
      "Validation Subset Distribution:\n",
      "\n",
      "Total samples in subset: 32\n",
      "Model ADM, Class nature: 3 (9.38%)\n",
      "Model ADM, Class ai: 1 (3.12%)\n",
      "Model BigGAN, Class nature: 3 (9.38%)\n",
      "Model BigGAN, Class ai: 1 (3.12%)\n",
      "Model Midjourney, Class nature: 3 (9.38%)\n",
      "Model Midjourney, Class ai: 1 (3.12%)\n",
      "Model VQDM, Class ai: 2 (6.25%)\n",
      "Model VQDM, Class nature: 2 (6.25%)\n",
      "Model glide, Class nature: 2 (6.25%)\n",
      "Model glide, Class ai: 2 (6.25%)\n",
      "Model stable_diffusion_v_1_4, Class nature: 1 (3.12%)\n",
      "Model stable_diffusion_v_1_4, Class ai: 3 (9.38%)\n",
      "Model stable_diffusion_v_1_5, Class nature: 1 (3.12%)\n",
      "Model stable_diffusion_v_1_5, Class ai: 3 (9.38%)\n",
      "Model wukong, Class ai: 4 (12.50%)\n",
      "\n",
      "Test Subset Distribution:\n",
      "\n",
      "Total samples in subset: 32\n",
      "Model ADM, Class ai: 1 (3.12%)\n",
      "Model ADM, Class nature: 3 (9.38%)\n",
      "Model BigGAN, Class ai: 1 (3.12%)\n",
      "Model BigGAN, Class nature: 3 (9.38%)\n",
      "Model Midjourney, Class ai: 1 (3.12%)\n",
      "Model Midjourney, Class nature: 3 (9.38%)\n",
      "Model VQDM, Class nature: 3 (9.38%)\n",
      "Model VQDM, Class ai: 1 (3.12%)\n",
      "Model glide, Class ai: 2 (6.25%)\n",
      "Model glide, Class nature: 2 (6.25%)\n",
      "Model stable_diffusion_v_1_4, Class nature: 3 (9.38%)\n",
      "Model stable_diffusion_v_1_4, Class ai: 1 (3.12%)\n",
      "Model stable_diffusion_v_1_5, Class ai: 3 (9.38%)\n",
      "Model stable_diffusion_v_1_5, Class nature: 1 (3.12%)\n",
      "Model wukong, Class nature: 3 (9.38%)\n",
      "Model wukong, Class ai: 1 (3.12%)\n"
     ]
    }
   ],
   "source": [
    "#check distribution of classes \n",
    "\n",
    "print(\"Check overlap between datasets:\\n\")\n",
    "print(\"\\nTrain Subset and Validation Subset:\")\n",
    "ut.check_data_overlap(train_subset, val_subset)\n",
    "print(\"\\nTrain Subset and Test Subset:\")\n",
    "ut.check_data_overlap(train_subset, test_subset)\n",
    "print(\"\\nValidation Subset and Test Subset:\")\n",
    "ut.check_data_overlap(val_subset, test_subset)\n",
    "\n",
    "print()\n",
    "print(\"\\nTrain Subset Distribution:\\n\")\n",
    "ut.print_model_class_distribution(train_dataset, train_subset.indices)\n",
    "print(\"\\nValidation Subset Distribution:\\n\")\n",
    "ut.print_model_class_distribution(val_test_dataset, val_subset.indices)\n",
    "print(\"\\nTest Subset Distribution:\\n\")\n",
    "ut.print_model_class_distribution(val_test_dataset, test_subset.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old smash and reconstruct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClassifier(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(BaseClassifier, self).__init__()\n",
    "        self.feature_combiner = ut.CNNBlock(kernels)\n",
    "        self.feature_combiner2 = ut.CNNBlock(kernels)\n",
    "        self.classifier = ut.DeepClassifier() \n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        outputs = self.classifier(feature_difference)\n",
    "\n",
    "        return outputs\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.feature_combiner = ut.CNNBlock(kernels)\n",
    "        self.feature_combiner2 = ut.CNNBlock(kernels)\n",
    "        resnet_weights = models.ResNet50_Weights.DEFAULT\n",
    "        self.resnet = models.resnet50(weights=resnet_weights)\n",
    "        # Remove the final fully connected layer\n",
    "        self.features = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "        # Add a new classifier layer\n",
    "        self.classifier = nn.Linear(self.resnet.fc.in_features, 2)\n",
    "        # Adaptive pool to make sure output from feature maps is of fixed size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        \n",
    "        # Process feature difference through the ResNet features\n",
    "        features = self.features(feature_difference)\n",
    "        pooled_features = self.adaptive_pool(features)\n",
    "        flat_features = torch.flatten(pooled_features, 1)\n",
    "        outputs = self.classifier(flat_features)\n",
    "\n",
    "        return outputs\n",
    "class SwinClassification(nn.Module):\n",
    "    def __init__(self,kernels):\n",
    "        super(SwinClassification, self).__init__()\n",
    "        self.feature_combiner = ut.CNNBlock(kernels)\n",
    "        self.feature_combiner2 = ut.CNNBlock(kernels)\n",
    "        config = SwinConfig.from_pretrained('microsoft/swinv2-tiny-patch4-window8-256',num_classes=2)\n",
    "        self.transformer = Swinv2ForImageClassification.from_pretrained(\n",
    "            \"microsoft/swinv2-tiny-patch4-window8-256\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        self.transformer.classifier = nn.Linear(config.hidden_size, 2) \n",
    "\n",
    " \n",
    "    def forward(self, rich, poor):\n",
    "       \n",
    "        x = self.feature_combiner(rich)\n",
    "        y = self.feature_combiner2(poor)   \n",
    "        feature_difference = x - y\n",
    "        outputs = self.transformer(feature_difference)\n",
    "\n",
    "        return outputs.logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frozen models old smash and reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type swinv2 to instantiate a model of type swin. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous best model with accuracy: 0.65625\n",
      "Epoch 1/10\n",
      ",Train Loss: 0.7018, Train Acc: 0.5338, Val Loss: 0.6918, Val Acc: 0.5625\n",
      "\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.6967, Train Acc: 0.5203, Val Loss: 0.6534, Val Acc: 0.6562\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.6697, Train Acc: 0.5912, Val Loss: 0.6615, Val Acc: 0.5625\n",
      "\n",
      "Epoch 4/10\n",
      ",Train Loss: 0.6707, Train Acc: 0.5574, Val Loss: 0.6542, Val Acc: 0.5312\n",
      "\n",
      "Epoch 5/10\n",
      ",Train Loss: 0.6710, Train Acc: 0.5980, Val Loss: 0.6550, Val Acc: 0.6562\n",
      "\n",
      "Epoch 6/10\n",
      ",Train Loss: 0.6563, Train Acc: 0.5946, Val Loss: 0.6484, Val Acc: 0.6875\n",
      "\n",
      "Saved new best model with accuracy: 0.6875\n",
      "Epoch 7/10\n",
      ",Train Loss: 0.6446, Train Acc: 0.6284, Val Loss: 0.6524, Val Acc: 0.6875\n",
      "\n",
      "Epoch 8/10\n",
      ",Train Loss: 0.6461, Train Acc: 0.6351, Val Loss: 0.6413, Val Acc: 0.6250\n",
      "\n",
      "Epoch 9/10\n",
      ",Train Loss: 0.6407, Train Acc: 0.6081, Val Loss: 0.6477, Val Acc: 0.6875\n",
      "\n",
      "Epoch 10/10\n",
      ",Train Loss: 0.6393, Train Acc: 0.6216, Val Loss: 0.6384, Val Acc: 0.6562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Swin Transformer\n",
    "learning_rates = [1e-3,1e-4, 1e-5, 1e-6]\n",
    "print(\"Training SWIN Transformer Frozen w/OLDSNR\\n\")\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kernels =  ut.apply_high_pass_filter()\n",
    "    model = SwinClassification(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_oldSMR_SWIN_frozen.pth'\n",
    "\n",
    "    #freeze the transformer layers\n",
    "    for param in model.transformer.parameters():\n",
    "        param.requires_grad = False\n",
    "    #unfreeze the classifier layer\n",
    "    for param in model.transformer.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous best model with accuracy: 0.65625\n",
      "Epoch 1/10\n",
      ",Train Loss: 0.7058, Train Acc: 0.4662, Val Loss: 0.6946, Val Acc: 0.4375\n",
      "\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.6938, Train Acc: 0.4865, Val Loss: 0.6919, Val Acc: 0.5312\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.6830, Train Acc: 0.5574, Val Loss: 0.6779, Val Acc: 0.6250\n",
      "\n",
      "Epoch 4/10\n",
      ",Train Loss: 0.6754, Train Acc: 0.6182, Val Loss: 0.6861, Val Acc: 0.5938\n",
      "\n",
      "Epoch 5/10\n",
      ",Train Loss: 0.6677, Train Acc: 0.6351, Val Loss: 0.6620, Val Acc: 0.5625\n",
      "\n",
      "Epoch 6/10\n",
      ",Train Loss: 0.6577, Train Acc: 0.6385, Val Loss: 0.6909, Val Acc: 0.5625\n",
      "\n",
      "Epoch 7/10\n",
      ",Train Loss: 0.6569, Train Acc: 0.6723, Val Loss: 0.6610, Val Acc: 0.5938\n",
      "\n",
      "Epoch 8/10\n",
      ",Train Loss: 0.6483, Train Acc: 0.6824, Val Loss: 0.6628, Val Acc: 0.5625\n",
      "\n",
      "Epoch 9/10\n",
      ",Train Loss: 0.6471, Train Acc: 0.6351, Val Loss: 0.6517, Val Acc: 0.6250\n",
      "\n",
      "Epoch 10/10\n",
      ",Train Loss: 0.6426, Train Acc: 0.6959, Val Loss: 0.6309, Val Acc: 0.6250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ResNET\n",
    "learning_rates = [1e-3,1e-4, 1e-5, 1e-6]\n",
    "print(\"Training RES Frozen w/OLDSNR\\n\")\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ResNetClassifier(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_oldSMR_RESNET_frozen.pth'\n",
    "    \n",
    "    #freeze resnet layers\n",
    "    for param in model.resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    #unfreeze the classifier layer\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unfreeze the pretrained models old reconstruct and destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous best model with accuracy: 0.78125\n",
      "Epoch 1/10\n",
      ",Train Loss: 0.6910, Train Acc: 0.5439, Val Loss: 0.6638, Val Acc: 0.6562\n",
      "\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.6215, Train Acc: 0.7095, Val Loss: 0.5954, Val Acc: 0.6875\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.5688, Train Acc: 0.7196, Val Loss: 0.5796, Val Acc: 0.7500\n",
      "\n",
      "Epoch 4/10\n",
      ",Train Loss: 0.5056, Train Acc: 0.7635, Val Loss: 0.5723, Val Acc: 0.6562\n",
      "\n",
      "Epoch 5/10\n",
      ",Train Loss: 0.4423, Train Acc: 0.7939, Val Loss: 0.4840, Val Acc: 0.7188\n",
      "\n",
      "Epoch 6/10\n",
      ",Train Loss: 0.4088, Train Acc: 0.8243, Val Loss: 0.5002, Val Acc: 0.7812\n",
      "\n",
      "Epoch 7/10\n",
      ",Train Loss: 0.3268, Train Acc: 0.8986, Val Loss: 0.4145, Val Acc: 0.8438\n",
      "\n",
      "Saved new best model with accuracy: 0.8438\n",
      "Epoch 8/10\n",
      ",Train Loss: 0.2740, Train Acc: 0.8750, Val Loss: 0.5531, Val Acc: 0.7812\n",
      "\n",
      "Epoch 9/10\n",
      ",Train Loss: 0.2369, Train Acc: 0.9122, Val Loss: 0.6411, Val Acc: 0.7500\n",
      "\n",
      "Epoch 10/10\n",
      ",Train Loss: 0.2105, Train Acc: 0.9358, Val Loss: 0.8387, Val Acc: 0.7188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ResNET\n",
    "print(\"Training RES UNFrozen w/OLDSNR\\n\")\n",
    "\n",
    "learning_rates = [1e-3,1e-4, 1e-5, 1e-6]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ResNetClassifier(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_oldSMR_RESNET_unfrozen.pth'\n",
    "\n",
    "\n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type swinv2 to instantiate a model of type swin. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous best model with accuracy: 0.78125\n",
      "Epoch 1/10\n",
      ",Train Loss: 0.7223, Train Acc: 0.5372, Val Loss: 0.6800, Val Acc: 0.5625\n",
      "\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.6928, Train Acc: 0.5135, Val Loss: 0.6636, Val Acc: 0.5625\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.6448, Train Acc: 0.5541, Val Loss: 0.6429, Val Acc: 0.7500\n",
      "\n",
      "Epoch 4/10\n",
      ",Train Loss: 0.6393, Train Acc: 0.6182, Val Loss: 0.6370, Val Acc: 0.5938\n",
      "\n",
      "Epoch 5/10\n",
      ",Train Loss: 0.6258, Train Acc: 0.6554, Val Loss: 0.6469, Val Acc: 0.5000\n",
      "\n",
      "Epoch 6/10\n",
      ",Train Loss: 0.6044, Train Acc: 0.6858, Val Loss: 0.6451, Val Acc: 0.6562\n",
      "\n",
      "Epoch 7/10\n",
      ",Train Loss: 0.6056, Train Acc: 0.6926, Val Loss: 0.7103, Val Acc: 0.5312\n",
      "\n",
      "Epoch 8/10\n",
      ",Train Loss: 0.6545, Train Acc: 0.5980, Val Loss: 0.6288, Val Acc: 0.6875\n",
      "\n",
      "Epoch 9/10\n",
      ",Train Loss: 0.5831, Train Acc: 0.6655, Val Loss: 0.6621, Val Acc: 0.6250\n",
      "\n",
      "Epoch 10/10\n",
      ",Train Loss: 0.5595, Train Acc: 0.6959, Val Loss: 0.5941, Val Acc: 0.6250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Swin Transformer\n",
    "print(\"Training SWIN UNFrozen w/OLDSNR\\n\")\n",
    "\n",
    "learning_rates = [1e-3,1e-4, 1e-5, 1e-6]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kernels =  ut.apply_high_pass_filter()\n",
    "    model = SwinClassification(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_oldSMR_SWIN_Unfrozen.pth'\n",
    "    \n",
    "    \n",
    "    \n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved model found. Starting fresh!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      ",Train Loss: 0.6858, Train Acc: 0.5811, Val Loss: 0.6958, Val Acc: 0.4688\n",
      "\n",
      "Saved new best model with accuracy: 0.4688\n",
      "Epoch 2/10\n",
      ",Train Loss: 0.6708, Train Acc: 0.6216, Val Loss: 0.7015, Val Acc: 0.4688\n",
      "\n",
      "Epoch 3/10\n",
      ",Train Loss: 0.6657, Train Acc: 0.5980, Val Loss: 0.6885, Val Acc: 0.5938\n",
      "\n",
      "Saved new best model with accuracy: 0.5938\n",
      "Epoch 4/10\n",
      ",Train Loss: 0.6448, Train Acc: 0.6284, Val Loss: 0.6584, Val Acc: 0.5938\n",
      "\n",
      "Epoch 5/10\n",
      ",Train Loss: 0.6305, Train Acc: 0.6318, Val Loss: 0.6088, Val Acc: 0.6562\n",
      "\n",
      "Saved new best model with accuracy: 0.6562\n",
      "Epoch 6/10\n",
      ",Train Loss: 0.6191, Train Acc: 0.6520, Val Loss: 0.5881, Val Acc: 0.6562\n",
      "\n",
      "Epoch 7/10\n",
      ",Train Loss: 0.6249, Train Acc: 0.6284, Val Loss: 0.5646, Val Acc: 0.7500\n",
      "\n",
      "Saved new best model with accuracy: 0.7500\n",
      "Epoch 8/10\n",
      ",Train Loss: 0.6116, Train Acc: 0.6486, Val Loss: 0.5392, Val Acc: 0.7812\n",
      "\n",
      "Saved new best model with accuracy: 0.7812\n",
      "Epoch 9/10\n",
      ",Train Loss: 0.5975, Train Acc: 0.6858, Val Loss: 0.5595, Val Acc: 0.6562\n",
      "\n",
      "Epoch 10/10\n",
      ",Train Loss: 0.5952, Train Acc: 0.6689, Val Loss: 0.5332, Val Acc: 0.6875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Original Model\n",
    "print(\"Training BASE w/OLDSNR\\n\")\n",
    "\n",
    "learning_rates = [1e-3,1e-4, 1e-5, 1e-6]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"Training with Learning Rate: {learning_rate} \\n\\n\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BaseClassifier(kernels).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_model_path = '/home/kosta/code/School/SentryAI/pth/best_model_oldSMR_Base.pth'\n",
    "\n",
    "\n",
    "    ut.train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_model_path= best_model_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
