{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na-ac-yCub9q",
        "outputId": "c0eea3cc-3c23-44b3-bd1e-c2a752d5d2cf"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45SO-ShDPtnp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "\n",
        "import timm\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image, ImageFilter\n",
        "import io\n",
        "import random\n",
        "import numpy.random as npr\n",
        "from skimage import data\n",
        "from scipy.ndimage import rotate\n",
        "import torchvision\n",
        "import os\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from transformers import Swinv2ForImageClassification, SwinConfig\n",
        "from torch.optim import AdamW\n",
        "from torchvision import transforms, datasets\n",
        "from preprocessing import smash_n_reconstruct, apply_high_pass_filter\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHLJwTVpQNfk"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "\n",
        "# Define the image transformations\n",
        "transformations = Compose([\n",
        "    Resize((224, 224)),  # EfficientNet typically uses 224x224 inputs\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # Convert image to PIL if it's not already\n",
        "    if not isinstance(image, Image.Image):\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "    # Apply smash and reconstruct and high pass filter\n",
        "    rich, poor = smash_n_reconstruct(image)\n",
        "    rich = apply_high_pass_filter(rich)\n",
        "    poor = apply_high_pass_filter(poor)\n",
        "\n",
        "    # Apply the resize, to tensor, and normalization transforms\n",
        "    rich = transformations(rich)\n",
        "    poor = transformations(poor)\n",
        "\n",
        "    return rich, poor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spj24sU8Tk0p"
      },
      "source": [
        "Preprocessing and Data loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZYWU2nlRR28"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_image(image):\n",
        "    rich, poor = smash_n_reconstruct(image)\n",
        "    rich = apply_high_pass_filter(rich)\n",
        "    poor = apply_high_pass_filter(poor)\n",
        "    return rich, poor\n",
        "\n",
        "\n",
        "class DatasetAI(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, split='train'):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.split = split  # This can be 'train', 'val', or 'test'\n",
        "        self.samples = []\n",
        "        self.label_count = {'ai': 0, 'nature': 0}\n",
        "\n",
        "        for model in sorted(os.listdir(root_dir)):\n",
        "            model_path = os.path.join(root_dir, model)\n",
        "            if os.path.isdir(model_path):\n",
        "                # Depending on the split, choose the appropriate subdirectory\n",
        "                split_folder = 'train' if split == 'train' else 'val'\n",
        "                data_dir = os.path.join(model_path, f'imagenet_{model.split(\"_\")[0]}', split_folder)\n",
        "                for class_label in ['ai', 'nature']:\n",
        "                    class_path = os.path.join(data_dir, class_label)\n",
        "                    if os.path.exists(class_path):\n",
        "                        for img_name in os.listdir(class_path):\n",
        "                            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                                img_path = os.path.join(class_path, img_name)\n",
        "                                self.samples.append((img_path, class_label))\n",
        "                                self.label_count[class_label] += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, class_label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        rich, poor = preprocess_image(image)  # Assume this function is defined elsewhere\n",
        "        if self.transform:\n",
        "            rich = self.transform(rich)\n",
        "            poor = self.transform(poor)\n",
        "        label = 0 if class_label == 'ai' else 1\n",
        "        return rich, poor, label\n",
        "\n",
        "def split_val_test_train(dataset_test_valid, dataset_train, train_size, val_size, test_size, seed=42):\n",
        "    rng = npr.default_rng(seed)\n",
        "    total_size_test_valid = len(dataset_test_valid)\n",
        "    total_size_train = len(dataset_train)\n",
        "\n",
        "    indices_test_valid = np.arange(total_size_test_valid)\n",
        "    indices_train = np.arange(total_size_train)\n",
        "\n",
        "    rng.shuffle(indices_test_valid)\n",
        "    rng.shuffle(indices_train)\n",
        "\n",
        "    if val_size + test_size > total_size_test_valid:\n",
        "        raise ValueError(\"Requested sizes for validation and test exceed available data\")\n",
        "    if train_size > total_size_train:\n",
        "        raise ValueError(\"Requested size for train exceeds available data\")\n",
        "\n",
        "    val_indices = indices_test_valid[:val_size]\n",
        "    test_indices = indices_test_valid[val_size:val_size + test_size]\n",
        "    train_indices = indices_train[:train_size]\n",
        "\n",
        "    val_subset = Subset(dataset_test_valid, val_indices)\n",
        "    test_subset = Subset(dataset_test_valid, test_indices)\n",
        "    train_subset = Subset(dataset_train, train_indices)\n",
        "\n",
        "    return train_subset, val_subset, test_subset\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    Resize((224, 224)),  # EfficientNet typically 224x224 inputs\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# # Create dataset instances\n",
        "# train_dataset = DatasetAI(root_dir='/mnt/d/GenImage', transform=transform, split='train')\n",
        "# val_test_dataset = DatasetAI(root_dir='/mnt/d/GenImage', transform=transform, split='val')\n",
        "\n",
        "\n",
        "# val_dataset, test_dataset ,train_dataset = split_val_test_train(val_test_dataset, train_dataset, 1000, 200, 200)\n",
        "\n",
        "# # Create DataLoader for each dataset\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yuE-PPwTjEZ"
      },
      "source": [
        "CNN Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsSI2Z_1TfZk"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CNNBlock(nn.Module):\n",
        "   def __init__(self, num_input_channels):\n",
        "       super(CNNBlock, self).__init__()\n",
        "       self.conv = nn.Conv2d(num_input_channels, 3, kernel_size=3, padding=1)\n",
        "       self.bn = nn.BatchNorm2d(3)\n",
        "       self.relu = nn.ReLU()\n",
        "   def forward(self, x):\n",
        "       x = self.conv(x)\n",
        "       x = self.bn(x)\n",
        "       x = self.relu(x)\n",
        "\n",
        "       return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LumXp1fYG2J"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GStsRmjAUWAd"
      },
      "outputs": [],
      "source": [
        "class ImageClassificationModel_EfficientNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ImageClassificationModel_EfficientNet, self).__init__()\n",
        "        self.feature_combiner = CNNBlock(num_input_channels=3)\n",
        "        self.feature_combiner2 = CNNBlock(num_input_channels=3)\n",
        "\n",
        "        # Initialize EfficientNet with the desired number of output classes\n",
        "        self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)\n",
        "\n",
        "        # Replace the classifier with a dummy since we have our own classifier\n",
        "        self.efficientnet.classifier = nn.Identity()\n",
        "\n",
        "        # Custom classifier that will take the output from EfficientNet\n",
        "        self.classifier = nn.Linear(self.efficientnet.get_classifier().in_features, num_classes)\n",
        "\n",
        "    def forward(self, rich, poor):\n",
        "        # Combine features from 'rich' and 'poor' textures using the CNN blocks\n",
        "        rich_features = self.feature_combiner(rich)\n",
        "        poor_features = self.feature_combiner2(poor)\n",
        "\n",
        "        # Calculate the feature difference\n",
        "        feature_difference = rich_features - poor_features\n",
        "\n",
        "        # Flatten the feature difference\n",
        "        feature_difference = feature_difference.view(feature_difference.size(0), -1)\n",
        "\n",
        "        # Pass the feature difference through EfficientNet to get the features\n",
        "        features = self.efficientnet(feature_difference)\n",
        "\n",
        "        # Pass the features through the custom classifier to get the logits\n",
        "        logits = self.classifier(features)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524,
          "referenced_widgets": [
            "6e413c4647424a7daa583e14e2967c82",
            "9f38ac729be94792aaa8c54e93562e2d",
            "7556fd1360314bec9b87ceeac55f65d2",
            "9567877d0f534225ac4696190d90d921",
            "a93844dcf229480984b55a2cf100cd2d",
            "e61ca79dfdb745e7bee8f6bdde32e736",
            "46e395aa5aed4c379548b3d137d6c4f9",
            "77ee2c2114b342c4ac6768257cdec97b",
            "c2d407ad491548a9bfdbc82cb7749699",
            "5b65aca068464a6887f250c002880857",
            "bc196f92bc7642d6b52cd954bb9454c6"
          ]
        },
        "id": "kZRyoXSrYNq4",
        "outputId": "2bb457c4-da7d-4d28-b826-037e982a64b3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ImageClassificationModel_EfficientNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW([\n",
        "    {'params': model.feature_combiner.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.feature_combiner2.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.efficientnet.parameters(), 'lr': 1e-5},  # To fine-tune EfficientNet\n",
        "    {'params': model.classifier.parameters(), 'lr': 1e-4},\n",
        "])\n",
        "#freeze the transformer\n",
        "\n",
        "# Initialize the best_val_accuracy variable\n",
        "best_val_accuracy = 0.0\n",
        "best_model_path = 'best_model.pth'\n",
        "\n",
        "# Try to load previous best model and its best validation accuracy\n",
        "try:\n",
        "    checkpoint = torch.load(best_model_path)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    best_val_accuracy = checkpoint['best_val_accuracy']\n",
        "    print(\"Loaded previous best model with accuracy:\", best_val_accuracy)\n",
        "except FileNotFoundError:\n",
        "    best_val_accuracy = float('-inf')\n",
        "    print(\"No saved model found. Starting fresh!\")\n",
        "\n",
        "def train_and_validate(model, train_loader, valid_loader, optimizer, device, num_epochs, best_val_accuracy):\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        total_train_loss, total_train, correct_train = 0, 0, 0\n",
        "        for batch in train_loader:\n",
        "            rich, poor, labels = batch\n",
        "            rich = rich.to(device)\n",
        "            poor = poor.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(rich, poor)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = total_train_loss / total_train\n",
        "        train_accuracy = correct_train / total_train\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        total_val_loss, total_val, correct_val = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for rich, poor, labels in valid_loader:\n",
        "                rich = rich.to(device)\n",
        "                poor = poor.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(rich, poor)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                total_val_loss += loss.item() * labels.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = total_val_loss / total_val\n",
        "        val_accuracy = correct_val / total_val\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
        "              f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        # Update the best model if current model is better\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            torch.save({'model_state': model.state_dict(),\n",
        "                        'best_val_accuracy': best_val_accuracy},\n",
        "                       best_model_path)\n",
        "            print(f\"Saved new best model with accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "#train_and_validate(model, train_loader, val_loader, optimizer, device, num_epochs=10, best_val_accuracy=best_val_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oqrhTJLu3-L"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "NQTd1TIXYhz2",
        "outputId": "c7eeb509-8678-4649-ce81-1468ac99cc29"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ImageClassificationModel_EfficientNet().to(device)\n",
        "def test(model, test_loader, device):\n",
        "    #load the best model\n",
        "    checkpoint = torch.load(\"best_model.pth\")\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "    model.eval()\n",
        "    total_test, correct_test = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for rich, poor, labels in test_loader:\n",
        "            rich = rich.to(device)\n",
        "            poor = poor.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(rich, poor)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = correct_test / total_test\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "#test(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La77zh7yu8PZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46e395aa5aed4c379548b3d137d6c4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b65aca068464a6887f250c002880857": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e413c4647424a7daa583e14e2967c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f38ac729be94792aaa8c54e93562e2d",
              "IPY_MODEL_7556fd1360314bec9b87ceeac55f65d2",
              "IPY_MODEL_9567877d0f534225ac4696190d90d921"
            ],
            "layout": "IPY_MODEL_a93844dcf229480984b55a2cf100cd2d"
          }
        },
        "7556fd1360314bec9b87ceeac55f65d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ee2c2114b342c4ac6768257cdec97b",
            "max": 21355344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2d407ad491548a9bfdbc82cb7749699",
            "value": 21355344
          }
        },
        "77ee2c2114b342c4ac6768257cdec97b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9567877d0f534225ac4696190d90d921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b65aca068464a6887f250c002880857",
            "placeholder": "​",
            "style": "IPY_MODEL_bc196f92bc7642d6b52cd954bb9454c6",
            "value": " 21.4M/21.4M [00:00&lt;00:00, 83.6MB/s]"
          }
        },
        "9f38ac729be94792aaa8c54e93562e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61ca79dfdb745e7bee8f6bdde32e736",
            "placeholder": "​",
            "style": "IPY_MODEL_46e395aa5aed4c379548b3d137d6c4f9",
            "value": "model.safetensors: 100%"
          }
        },
        "a93844dcf229480984b55a2cf100cd2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc196f92bc7642d6b52cd954bb9454c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2d407ad491548a9bfdbc82cb7749699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e61ca79dfdb745e7bee8f6bdde32e736": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
